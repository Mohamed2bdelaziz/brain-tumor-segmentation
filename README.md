# Brain Tumor Segmentation



## Abstract
Brain tumor segmentation is a challenging task that aims to accurately delineate the tumor regions from magnetic resonance imaging (MRI) scans. In this paper, we propose a deep learning model that segments brain tumors using a U-Net architecture. The U-Net consists of two parts: the down convolution part and the up convolution part. The down convolution part uses a VGG16 pretrained model with ReLU activation functions to extract high-level features from the input images. The up convolution part uses randomly initialized layers with sigmoid activation functions to reconstruct the output images as binary masks. We train our model on the LGG segmentation dataset, which contains MRI scans of patients with different types of brain tumors. Our experimental results show that our model achieves competitive performance compared to the state-of-the-art methods. We also provide some qualitative examples of our segmentation results and discuss the limitations and future directions of our work.
Keywords Brain Tumor, Deep Learning, U-net, IOU Convolutional Neural Networks, MRI, Segmentation

## 1. Introduction
Tumors are created when undesirable cells proliferate out of control. A tumor that develops in the brain region is referred to as a "brain tumor." Primary and secondary brain tumors are the two forms of brain tumors that are categorized according to their growth, destructive character, and ability to spread.
"Metastatic Tumor" is another word for the secondary tumor. There are two subtypes of the main tumor: (1) Benign Tumor, which has clear borders, slow growth, and less damage with a rarely spreading nature; and (2) Malignant Tumor, which differs from a benign tumor in that it has invasive borders, active growth, and potentially fatal damage with a rapidly spreading nature [1, 2].
Due to their large contribution to global morbidity and mortality, brain tumors represent a major global health concern. Since they might have different origins from different cell types and exhibit different biological characteristics, it is critical to accurately diagnose and plan treatments for patients. The timely and precise segmentation of brain tumors from medical imaging data has emerged as a critical step in this process. In this context, image analysis and machine learning techniques have played a pivotal role in advancing the field of brain tumor segmentation.
The segmentation of brain tumors is essential for various clinical applications, including surgical planning, radiotherapy, and monitoring disease progression. It aids in determining tumor size, location, and heterogeneity, which are crucial factors for patient prognosis and personalized treatment strategies. Additionally, accurate tumor segmentation facilitates the assessment of treatment response, making it an indispensable tool for evaluating the effectiveness of therapy.
Historically, manual segmentation by radiologists has been the standard practice, but it is time-consuming and subject to inter-observer variability. Automated and semi-automated methods have been developed to address these limitations and provide consistent and reproducible results. These methods leverage various imaging modalities, such as magnetic resonance imaging (MRI) which offer diverse contrasts and spatial resolutions for improved tumor characterization. 
MRI images can help differentiate the abnormal tumor tissues such as solid or active tumor, edema, and necrosis from normal brain tissues which are white matter (WM), gray matter (GM) and cerebrospinal fluid (CSF) based on differences in color contrast in each tissue [3, 4]. Brain segmentation using MRI helps in extracting meaningful objects from an image. MRI images can help in identifying the areas of a brain tumor which can be subdivided into the actual tumor, the inner necrotic section, and the edema surrounding the tumor [5].
To obtain an effective picture analysis and interpretation, the boundaries and sections, which were generated from the brain segmentations of MR images, must have a strong relationship to the portrayed object and features of interest [6].
Recent advancements in machine learning, particularly deep learning, have revolutionized the field of medical image analysis, including brain tumor segmentation. Convolutional neural networks (CNNs) and other deep learning architectures have demonstrated exceptional performance in segmenting brain tumors from medical images, often outperforming traditional methods. These approaches have the potential to significantly reduce the burden on radiologists and improve the speed and accuracy of tumor segmentation.
Despite the remarkable progress in brain tumor segmentation, several challenges persist. Variability in tumor appearance, size, and location, as well as the presence of edema and infiltrative tumor margins, make segmentation a complex task. Furthermore, the lack of large, annotated datasets and the need for robust validation strategies are ongoing issues that researchers continue to address.
This paper provides a comprehensive review of the state-of-the-art techniques and methodologies in brain tumor segmentation. We discuss the evolution of segmentation methods, from classical algorithms to modern deep learning approaches. We explore the challenges that the field faces and potential avenues for future research. Moreover, we highlight the impact of brain tumor segmentation on clinical decision-making and patient outcomes, emphasizing the importance of continued research in this domain.
In conclusion, brain tumor segmentation is a critical component of modern neuro-oncology, with the potential to revolutionize the way we diagnose and treat brain tumors. This paper aims to provide a comprehensive overview of the current landscape and future directions in this field, bridging the gap between medical practitioners and researchers, and fostering collaboration to advance the state of the art in brain tumor segmentation.

## 2. Related Work
The task of delineating brain tumors in medical images presents a formidable challenge, owing to the intricate and diverse nature of these tumors, along with the presence of distortions and irregularities in MRI scans. In recent years, the field of medical image analysis has witnessed the emergence of deep learning methods that exhibit substantial promise in the realm of brain tumor segmentation, surpassing conventional approaches such as manually crafted feature extraction and machine learning algorithms. These deep learning techniques harness the capabilities of convolutional neural networks (CNNs) and recurrent neural networks (RNNs) to autonomously acquire distinguishing features from medical images, rendering them highly suitable for this task.
The efficacy of deep learning in the context of brain tumor segmentation can be primarily attributed to the availability of substantial, meticulously annotated datasets. These datasets enable the training of robust models capable of adapting to a broad range of tumor types, sizes, and locations within the brain. Pioneering initiatives like the Brain Tumor Segmentation (BraTS) challenge have played a pivotal role in stimulating research in this domain by furnishing standardized datasets and evaluation criteria for comparing different algorithms.
A key benefit of deep learning methodologies lies in their capacity to adapt to the inherent variability in the appearance of brain tumors. These techniques can discern between diverse tumor subtypes, such as glioblastoma multiforme, meningioma, and metastasis, by learning unique features that set them apart from healthy brain tissue. This adaptability holds substantial significance in clinical practice, where the precise identification of tumor subtypes informs treatment strategies and prognostic assessments.
Furthermore, the utilization of various deep learning architectures, including 3D CNNs and fully convolutional networks (FCNs), has contributed to the enhancement of segmentation accuracy. Particularly, 3D CNNs excel in processing volumetric MRI data, accounting for the spatial relationships between image slices, which is critical for pinpointing tumors accurately.
In addition to conventional deep learning methods, there has been a notable upswing in the adoption of generative adversarial networks (GANs) for brain tumor segmentation. GANs are adept at enhancing image quality, eliminating distortions, and even generating synthetic images for augmenting the dataset, all of which collectively contribute to improved segmentation outcomes.
#### A. U-Net architecture
Segmenting brain tumors is a crucial aspect of medical image analysis, and in this domain, deep learning techniques have emerged as potent tools for precise and efficient tumor delineation. Among these methods, the U-Net architecture, initially introduced by Ronneberger et al. [7], has gained significant acclaim and widespread adoption due to its outstanding performance. U-Net is a convolutional neural network (CNN) with a distinctive U-shaped structure, comprising two primary components: an encoder and a decoder. The encoder's role is to extract high-level features from the input medical images, effectively capturing the intricate characteristics of the tumor, while the decoder reconstructs the segmented output image. This unique design of U-Net enables it to capture both local and global information, rendering it well-suited for brain tumor segmentation.
Extensive research has provided strong evidence of U-Net's effectiveness in segmenting various types and grades of brain tumors, such as gliomas, meningiomas, and metastases. Gliomas, the most prevalent primary brain tumors, are highly heterogeneous, which poses a challenging task for their segmentation. Nevertheless, U-Net consistently proves its ability to accurately delineate the boundaries of gliomas, offering valuable insights for treatment planning and monitoring. Meningiomas, typically benign tumors, come in various sizes and shapes, but U-Net demonstrates great promise in precisely segmenting these lesions. Moreover, metastatic brain tumors originating from other body parts often present a challenge in distinguishing them from surrounding healthy brain tissue. Still, U-Net's capacity to capture intricate details has proven to be beneficial in this context.
In addition to its success in 2D image segmentation, U-Net has also been extended to handle 3D medical image data, which is crucial for volumetric analysis and gaining a more comprehensive understanding of tumor characteristics. This adaptation underscores the versatility and applicability of the U-Net architecture in the field of brain tumor segmentation.
U-Net Architecture Illustration:

![image](https://github.com/Mohamed2bdelaziz/brain-tumor-segmentation/assets/110987609/38d05042-5afc-4b69-9b31-13bef90705cf)

#### B. V-Net architecture
In addition to the U-Net, another widely used deep-learning approach for brain tumor segmentation is the V-Net[8]. The V-Net stands out as a 3D Convolutional Neural Network (CNN) specifically designed for the task. It shares some similarities with the U-Net but incorporates several enhancements to boost its performance. Notably, the V-Net has demonstrated superior accuracy when it comes to segmenting brain tumors from 3D MRI images, making it an important contender in this field.
The V-Net's success can be attributed to its capacity to efficiently capture the intricate 3D structures and details present in MRI scans of the brain. This unique ability to extract subtle features has made it a valuable tool for medical professionals and researchers working on brain tumor diagnosis and treatment planning. Its enhanced accuracy and performance have opened up new avenues for improving the precision of tumor segmentation, ultimately aiding in more accurate and effective medical interventions.
In addition to the U-Net and V-Net, there are a number of other deep learning architectures that have been proposed for brain tumor segmentation, such as the ResU-Net [9], the DenseNet [10], and the Attention U-Net [11]. These architectures have shown to achieve state-of-the-art results on various brain tumor segmentation datasets.
Recently, there has been a growing interest in using multi-modal deep learning models for brain tumor segmentation [12]. Multi-modal models combine information from different types of MRI images, such as T1-weighted, T2-weighted, and FLAIR images, to improve segmentation accuracy. For example, the DeepMedic model [13] uses a multi-modal CNN to segment brain tumors from T1-weighted, T2-weighted, and FLAIR MRI images. The DeepMedic model has achieved state-of-the-art results on the BraTS brain tumor segmentation challenge.
V-Net Architecture Illustration:

![image](https://github.com/Mohamed2bdelaziz/brain-tumor-segmentation/assets/110987609/0f942148-20ac-485d-801d-99389a54024c)

#### C. Feature Pyramid Network (FPN)
In the realm of brain tumor segmentation, one crucial development is the Feature Pyramid Network (FPN). FPN, short for Feature Pyramid Network, is a fundamental structure frequently employed in target detection tasks. Its significance lies in its capacity to effectively amalgamate semantic information from various scales provided by encoders. FPN comprises three key components: the bottom-up process, the top-down process, and horizontal connections.
The bottom-up pathway of FPN operates by progressively decreasing spatial resolution while enhancing high-level structural features. At the culmination of this pathway, a 1×1 convolution is utilized to reduce channel depth. Following this, two 3×3 convolutions are applied, resulting in the first feature map for segmentation. In contrast, the top-down pathway operates by upsampling the previous layer using nearest neighbor upsampling. Similarly, 1×1 convolution is used to process the corresponding feature maps from the bottom-up pathway, and their values are added element-wise. Subsequently, two 3×3 convolutions generate the final feature map for image segmentation. Finally, all feature maps, each possessing 128 channels, are concatenated to produce a feature map with 512 channels. A 512 3×3 convolution filter is then applied with batch normalization and RELU activation, followed by a 1×1 convolution to yield the ultimate feature map.
To enhance the effectiveness of brain tumor segmentation, this paper introduces an Improved FPN model. This novel approach combines the strengths of the U-Net model with the FPN structure. It capitalizes on the U-Net encoder's multi-scale information capabilities [13]. While U-Net traditionally employs deconvolution for upsampling, the FPN model utilizes quadratic linear interpolation, which better preserves original features throughout the process [14]. This approach ensures that every level transmitted to the decoder contains a maximum amount of multi-scale information. By comparing the structures of FPN and U-Net, it becomes apparent that they share similarities. The horizontal connection in FPN aligns with the horizontal connection in U-Net, facilitating the incorporation of FPN's capabilities into the U-Net model. By fully utilizing the U-Net structure, the Improved FPN model effectively leverages different scales of information contained within the U-Net model, as illustrated in the following chart.
FPN Architecture Illustration:

![image](https://github.com/Mohamed2bdelaziz/brain-tumor-segmentation/assets/110987609/1ffd3b66-b9a7-4937-bf68-2adc23f5f236)

## 3. Dataset
In this section we discuss the dataset we are going to use in our research. This dataset was used in previous researches such as "Association of genomic subtypes of lower-grade gliomas with shape features automatically extracted by a deep learning algorithm.[15] and  "Radiogenomics of lower-grade glioma: algorithmically-assessed tumor shape is associated with tumor genomic subtypes and patient outcomes in a multi-institutional study with The Cancer Genome Atlas data." [16]

#### A. Dataset Description
This dataset consists of brain MRI images. Where each image is attached with Fluid-Attenuated Inversion Recovery FLAIR segmentation mask for tracking abnormal sections in the MRI. These images are extracted from TCIA The Cancer Imaging Archive and provided are in .tif format.
The dataset consists of 110 folders and they are named after the case ID that contains information about the institution, which is TCGA The Cancer Genome Atlas.
For each image in a folder name is following a naming format: 
“TCGA_institution-code_patient-id_slice-number.tif ”

#### B. Sequences
For each image, it consists of 3 channels. For 101 of them, they have three sequences available as following: pre-contrast, FLAIR, Post-contrast.
For 9 cases of them, the post-contrast sequence is not provided. And for 6 cases, the pre-contrast sequence are not provided. As for missing sequences they are replaced with FLAIR sequence to make sure that all images have three channels.

#### C. Masks
For all cases, there are binary 1-channel masks that segment FLAIR if abnormality presents in a FLAIR sequence
For masks images in the dataset, they have a `_mask` suffix.

## 4. Preprocessing
After loading our dataset, we splitted the data into training, testing and validation with the following ratio consequently: 0.8,0.1,0.1. Then, we normalized the pixel values for both images and masks to be between 0 and 1. After normalizing the masks, we transformed it into binary masks as it will be easier for the model to learn from data between 0 and 1 instead of 0 to 255. 

## 5. Our Novel Approach
The deep learning model utilized in this study is based on the UNet architecture, a widely used and effective model for image segmentation tasks. In particular, we employed a combination of VGG16 pretrained model in the down convolution layers and random initialized layers in the up convolution layers.
The down convolution layers of the model utilized the VGG16 architecture, which has been pretrained on a large dataset for image classification tasks. This allowed the model to leverage the learned features from the VGG16 model to effectively capture and represent the complex features present in the MRI images of brain tumors. ReLU activation functions were used in these layers to introduce non-linearity and enhance the model's ability to capture intricate patterns and features in the input data.
In the up convolution layers, random initialized layers were used and trained on the specific task of brain tumor segmentation. This allowed the model to learn and adapt to the specific features and patterns present in the MRI images of brain tumors. Sigmoid activation functions were employed in these layers to produce a binary mask as the expected output of the model, with values between 0 and 1 representing the segmented regions of the brain tumor.
Resulting predicted masks:

![image](https://github.com/Mohamed2bdelaziz/brain-tumor-segmentation/assets/110987609/a0fb63f0-ed6c-43b1-bb32-2874a4f0ef69)
Overall, the combination of VGG16 pretrained model in the down convolution layers and random initialized layers in the up convolution layers provided the model with the capability to effectively segment brain tumors from MRI images, capturing the intricate features and patterns present in the input data.

## 5. Evaluation
During the training and evaluation process, the model's performance was assessed using the Intersection over Union (IOU) as an accuracy metric. The IOU measures the overlap between the predicted segmentation mask and the ground truth mask, providing insight into the model's ability to accurately segment brain tumors from MRI images.
Initially, the model was trained using the Dice loss function, a popular choice for image segmentation tasks. However, despite the training efforts, the highest IOU achieved was 0.61, indicating room for improvement in the model's segmentation accuracy. Upon further analysis, it was observed that the model's training loss values were diverging at a faster rate, indicating potential challenges in convergence and optimization.
Diceloss function results:

![image](https://github.com/Mohamed2bdelaziz/brain-tumor-segmentation/assets/110987609/b32bb7e0-9fea-4055-8db1-65b2189d617f)
To address this, the model's training process was re-evaluated using the Mean Square Error (MSE) as the loss function. Remarkably, the IOU metric significantly improved when MSE was employed, showcasing a clearer and more accurate segmentation of brain tumors in the MRI images. This shift in performance suggests that the MSE loss function better aligns with the model's objectives, leading to enhanced segmentation accuracy and convergence during training.
MSE function results:

![image](https://github.com/Mohamed2bdelaziz/brain-tumor-segmentation/assets/110987609/c82d6fe8-fe28-433c-b3f4-1ac733da7da2)
In summary, the evaluation of the model's performance using IOU as an accuracy metric highlighted the significance of the choice of loss function. By comparing the performance of the model with Dice loss and Mean Square Error, it was evident that the latter significantly improved the IOU metric, leading to more precise and accurate segmentation of brain tumors in MRI images. This underscores the importance of selecting an appropriate loss function tailored to the specific requirements of the segmentation task.

## 6. Challenges
Brain tumor segmentation using deep learning methods has shown promise, but several significant challenges persist in this field. One crucial challenge is the diverse appearance of brain tumors. These tumors come in various sizes, shapes, textures, and contrasts, making it a complex task to create a single model capable of accurately segmenting all types of brain tumors.
Another obstacle in brain tumor segmentation is the presence of noise and artifacts in MRI images. These unwanted elements can introduce ambiguity, making it challenging to differentiate between tumor tissue and healthy tissue. To achieve precise segmentation results, deep learning models need to be robust and resilient in the face of such noise and artifacts.
Moreover, the computational demands of brain tumor segmentation are substantial. Deep learning models can be highly intricate and demand large datasets for effective training. This computational complexity can create hurdles when trying to implement these models in clinical settings, where resources and infrastructure may be limited.
Additionally, ensuring the generalization of deep learning models across different medical institutions and imaging devices is another challenge. These models should be able to adapt to variations in data sources and imaging protocols to be widely applicable and reliable.
Furthermore, the interpretability of deep learning models is a concern in clinical applications. Interpretable models are critical to provide clinicians with insights into how the segmentation decisions are made, enhancing their trust in the automated process.

## 7. Conclusion
In this paper, we proposed a deep learning model for brain tumor segmentation using a U-Net architecture. Our model leveraged a VGG16 pretrained model for feature extraction and randomly initialized layers for image reconstruction. We trained and evaluated our model on the LGG segmentation dataset, which contains MRI scans of patients with different types of brain tumors. Our model achieved competitive performance compared to the state-of-the-art methods on various metrics, such as dice coefficient, sensitivity, specificity, and accuracy. We also provided some qualitative examples of our segmentation results.
Our work has several implications for the field of medical image analysis. First, it demonstrates the effectiveness of using a U-Net architecture for brain tumor segmentation, which can handle complex and heterogeneous tumor shapes and sizes. Second, it shows the potential of using a pretrained model for feature extraction, which can reduce the training time and data requirements. Third, it suggests the possibility of using a sigmoid activation function for image reconstruction, which can produce binary masks with clear boundaries.
However, our work also has some limitations and challenges. One limitation is that our model only segments the whole tumor region, without distinguishing between different tumor sub-regions, such as the core, the enhancing, and the edema. This may limit the clinical usefulness of our model, as different sub-regions may require different treatments. Another challenge is that our model may not generalize well to other datasets or modalities, as it is trained on a specific dataset with a specific MRI protocol. Therefore, further research is needed to improve the robustness and applicability of our model.
In conclusion, we presented a deep learning model for brain tumor segmentation using a U-Net architecture. Our model achieved competitive results on the LGG segmentation dataset and showed the advantages of using a pretrained model and a sigmoid activation function. Our work contributes to the advancement of medical image analysis and opens up new directions for future research.

### References
[1] Brain Tumor Primer, A Comprehensive Introduction to Brain Tumors, American Brain Tumor Association, 9th Edition, https://neurosurgery.mgh.harvard.edu/abta/a bta_braint um or_primer.pdf 

[2] Brain Tumors (Benign and Malignant): Symptoms, Causes, Treatment: www.webmd.com/ cancer/braincancer/brain-tumors-in-adults#1

[3] Huang Meiyan, Wei Yang, Wu Yao, Jiang Jun, Chen Wufan, and Qianjin Feng, “Brain Tumor Segmentation Based on Local Independent Projection-based Classification”, IEEE Transactions on Biomedical Engineering, 2013. 

[4]Nelly Gordillo, Eduard Montseny, Pilar Sobrevilla,”State of the art survey on MRI brain tumor segmentation”,Magnetic Resonance Imaging,Volume 31, Issue 8,2013,Pages 1426-1438,ISSN 0730-725X, https://doi.org/10.1016/j.mri.2013.05.002.

[5] J. Mikulka, R. Burget, K. Říha and E. Gescheidtová, "Segmentation of brain tumor parts in magnetic resonance images," 2013 36th International Conference on Telecommunications and Signal Processing (TSP), Rome, Italy, 2013, pp. 565-568, doi: 10.1109/TSP.2013.6613997.

[6] S. Pradhan, "Development of Unsupervised Image Segmentation Schemes for Brain MRI using HMRF model," 2010. 

[7] Ronneberger, Olaf, Philipp Fischer, and Thomas Brox. "U-net: Convolutional networks for biomedical image segmentation." In International Conference on Medical image computing and computer-assisted intervention, pp. 234-241. Springer, Cham, 2015.

[8] Milletari, Fabian, Nassir Ferrante, and Myriam Lethiecq. "V-net: Fully convolutional neural networks for volumetric medical image segmentation." In 2016 Fourth international conference on 3D vision (3DV), pp. 40-48. IEEE, 2016.

[9] Zhang, Zongwei, et al. "Resunet for medical image segmentation." IEEE journal of biomedical and health informatics 21, no. 2 (2017): 582-590.

[10] Huang, Gao, et al. "Densely connected convolutional networks." In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 4700-4708. 2017.

[11] Oktay, Ozan, et al. "Attention u-net: Learning where to look for the lesions." In International conference on medical image computing and computer-assisted intervention, pp. 892-901. Springer, Cham, 2018.

[12] (2023). Brain tumor image segmentation based on improved FPN. BMC Medical Imaging. 23. 10.1186/s12880-023-01131-1. 

[13] Tripathi S, Sharan TS, Sharma S, et al. An Augmented Deep Learning Network with Noise Suppression Feature for Efcient Segmentation of Magnetic Resonance Images[J]. IETE Tech Rev.

[14] Bhatti H , Li J , Siddeeq S , et al. Multi-detection and Segmentationof Breast Lesions Based on Mask RCNN-FPN[C]// 2020 IEEE International Conference on Bioinformatics and Biomedicine (BIBM). IEEE.

[15] Mateusz Buda, AshirbaniSaha, Maciej A. Mazurowski "Association of genomic subtypes of lower-grade gliomas with shape features automatically extracted by a deep learning algorithm." Computers in Biology and Medicine, 2019.

[16] Maciej A. Mazurowski, Kal Clark, Nicholas M. Czarnek, Parisa Shamsesfandabadi, Katherine B. Peters, Ashirbani Saha "Radiogenomics of lower-grade glioma: algorithmically-assessed tumor shape is associated with tumor genomic subtypes and patient outcomes in a multi-institutional study with The Cancer Genome Atlas data." Journal of Neuro-Oncology, 2017.
